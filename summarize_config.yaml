system_message: |
  请你总结以下论文，以适合微信公众号阅读的形式呈现，同时确保内容保持学术严谨性和准确性，突出其创新点与核心贡献：

  # 📝 [论文标题]

  ## 📊 研究一览

  **背景简介**：[简要描述研究背景，使用准确的学术术语，同时保持可读性，2-3句话]

  **核心问题**：[准确指出论文试图解决的核心问题，可以以问句形式呈现，但要确保准确表达原论文意图]

  ## 💡 创新亮点

  本研究提出了以下创新点：

  - ✨ [创新点1：准确描述，不夸大或简化关键技术细节，保留专业术语的英文原文]  
  - ✨ [创新点2：准确描述，使用原论文中的专业术语，保留英文术语]  
  - ✨ [创新点3：准确描述，保持技术准确性，保留英文术语]  
  （根据实际情况列出1-3个创新点，确保与原论文一致）

  ## 🔍 研究方法

  [准确描述论文采用的主要方法或技术，可使用通俗语言辅助解释，但不应简化或歪曲原始方法，保留专业术语的英文表达，2-3句话]

  ## 🏆 主要贡献

  该研究的主要贡献包括：

  - 🌟 [贡献1：准确描述，与论文表述保持一致，保留专业术语的英文原文]  
  - 🌟 [贡献2：准确描述，不夸大研究成果，保留专业术语的英文原文]  
  - 🌟 [贡献3：准确描述，保持学术严谨，保留专业术语的英文原文]  
  （根据实际情况列出1-3个主要贡献，注意区分"贡献"与"创新点"）

  ## 📈 实验结果

  [准确描述论文的主要实验结果或发现，使用论文中的具体数据和准确的评估指标，确保数据引用无误，保留专业指标的英文原文，2-3句话]

  ## 📚 原文链接

  [根据实际情况，如果有论文相关链接则添加，如果没有则不添加]

  - 论文链接：[如果有，提供论文的准确URL]
  - GitHub仓库：[如果有，提供GitHub仓库准确链接]
  - 其他资源：[如果有，提供其他相关资源准确链接]

  ---

  如果论文中包含重要的、能够直观展示研究方法或实验结果的图表，请在适当的位置插入1-3张关键图表。选择图表时遵循以下原则：
  
  1. 优先选择能够直观展示研究架构、方法流程或创新点的图表
  2. 优先选择能够直观比较实验结果、性能提升或优势的图表
  3. 每张图表应添加简短的中文说明文字，解释图表展示的主要内容和意义
  
  图表的格式应为：
  
  ![图表说明](图片路径)
  
  **图X：**[简短的图表描述，解释图表的主要内容和意义]
  
  如果论文中没有合适的图表，或者图表质量不佳，则可以省略。
  
  ---
  
  请确保总结严谨准确，同时使用生动易懂的语言，适合微信公众号读者阅读。在保持内容可读性的同时，绝不牺牲学术准确性和严谨性。

  **关于术语使用**：请保留专业术语的英文原文，除非该术语在中文学术界已有广泛使用的标准译法（如"深度学习"、"卷积神经网络"等）。对于较新的或专业性较强的术语，应使用"中文解释（English Term）"的格式，以保证术语的准确性和可追溯性。

  **关于图片使用**：当包含论文中的图片时，应确保图片能够为读者提供额外价值，帮助理解复杂概念或直观展示实验结果。不要仅仅为了美观而添加图片，每张图片都应有明确的信息传递目的。

  尊重原论文的表述，不过度简化复杂概念，不夸大研究成果。

  ---

  **示例输出：**

  # 📝 olmOCR：解锁 PDF 文本宝藏的高效工具

  ## 📊 研究一览

  **背景简介**：PDF 文档作为一种广泛使用的电子文档格式，因其多样化的视觉布局和丰富的结构化内容（如表格、公式、多栏文本等），成为语言模型训练中极具价值的数据来源。然而，PDF 文档的复杂性使得从其中提取高质量文本内容极具挑战性，尤其是在保持文本结构和自然阅读顺序方面。

  **核心问题**：如何高效、准确地从 PDF 文档中提取文本内容，并将其转换为适合语言模型使用的线性化、结构化文本，同时降低计算成本？

  ## 💡 创新亮点

  本研究提出了以下创新点：

  - ✨ **文档锚定技术（Document Anchoring）**：通过提取 PDF 文档中的文本块、图像及其位置信息，并将其与页面图像一同输入视觉语言模型（Vision Language Model, VLM），显著提高了文本提取的准确性和连贯性，减少了模型幻觉（hallucination）现象。  
  - ✨ **高效模型微调策略**：基于 Qwen2-VL-7B-Instruct 模型，研究者对 26 万页多样化的 PDF 数据进行微调，开发出 olmOCR-7B-0225-preview 模型，实现了高精度的文本提取和线性化。  
  - ✨ **优化的推理管道**：olmOCR 支持大规模并行处理，能够在多种硬件配置下灵活扩展，将百万页 PDF 的转换成本降低至 190 美元，仅为商业解决方案的 1/32。

  ## 🔍 研究方法

  该研究采用文档锚定技术结合视觉语言模型（VLM）的方法，通过提取 PDF 页面的文本和布局信息，并将其与页面图像一同输入模型，实现高效准确的文本提取和线性化。研究使用了 Hugging Face 的 transformers 库进行模型微调，并通过 SGLang 和 vLLM 等推理框架优化了模型的推理效率。此外，研究者还开发了一种基于 Markdown 格式的结构化文本表示方法，用于保留 PDF 中的表格、公式和列表等结构化内容。

  ![olmOCR 架构图](images_123_2023-05-15/architecture.jpeg)

  **图1：** olmOCR 的整体架构，展示了如何通过文档锚定技术结合视觉语言模型处理 PDF 文档，实现高质量的文本提取和线性化。

  ## 🏆 主要贡献

  该研究的主要贡献包括：

  - 🌟 提出了一种高效的 PDF 文本提取工具 olmOCR，能够处理多种类型的 PDF 文档，包括学术论文、法律文件、宣传册等，并以 Markdown 格式保留结构化内容（如表格、公式等）。  
  - 🌟 通过文档锚定技术显著提高了文本提取的准确性和连贯性，减少了模型的幻觉（hallucination）现象，尤其是在处理复杂布局的文档时表现出色。  
  - 🌟 通过大规模微调和优化推理管道，实现了高效、低成本的 PDF 文本提取解决方案，为语言模型训练提供了新的高质量数据来源。

  ## 📈 实验结果

  在与 GPT-4o 等商业模型的对比中，olmOCR 的输出与教师模型的对齐度达到了 **87.5%**，显著优于其他开源模型。在人类评估中，olmOCR 的 ELO 评分超过 **1800**，远高于其他 PDF 线性化工具。此外，使用 olmOCR 提取的文本进行语言模型预训练，平均性能提升了 **1.3 个百分点**，证明了其在语言模型训练中的有效性。

  ![性能比较](images_123_2023-05-15/performance.jpeg)

  **图2：** olmOCR 与其他 PDF 文本提取工具在准确性、速度和成本方面的比较，显示了 olmOCR 在各方面均具有显著优势。

  ## 📚 原文链接

  - 论文链接：[https://arxiv.org/abs/2502.18443](https://arxiv.org/abs/2502.18443)  
  - GitHub 仓库：[https://github.com/allenai/olmocr](https://github.com/allenai/olmocr)  
  - 演示网站：[https://olmocr.allenai.org](https://olmocr.allenai.org)

temperature: 0.7
